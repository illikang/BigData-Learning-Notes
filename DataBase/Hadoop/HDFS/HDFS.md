# Hadoop分布式文件系统

## 前言
当我们的数据集的大小超过了单机容量的极限时，就需要把数据拆分并存储在不同的机器上。
而管理跨机器之间数据存储的文件系统就被称为分布式文件系统(Distributed Filesystem)。
HDFS(Hadoop Distribute Filesystem)正是Hadoop的旗舰型文件管理系统，它是Hadoop框架的核心组件之一，主要用于实现分布式文件管理。

## HDFS概要
HDFS设计的初衷是：在廉价的商用集群上，通过流数据访问的方式实现超大文件的存储。有是三个突出特点：
1. 超大文件：文件在G，百G甚至是百T级别。
2. 流数据访问:HDFS是基于一次写入，多次读取这种最高效的数据处理模式（流数据模式）创建的。
3. 廉价的商业集群：Hadoop并不要求价格高昂、高稳定的机器。即使在廉价的、故障率较高的廉价集群上，hadoop也能很好得完成工作。Hadoop有完善的机制处理异常问题。

然而，在带来这些便利的同时，HDFS的一些特性也使得它无法满足以下的应用场景：
1. 低延迟数据访问：HDFS是基于高数据通量，而不是高通率的理念设计的，高延迟是无法避免。Hbase是低延迟的要求的更佳选择。
2. 数据是大量小文件：由于文件系统的元数据都是存储在内存中的名称节点（namenode）上，因此可管理文件的数量就受限于内存大大小。
3. 数据有多个写入者，并需要任意次修改：HDFS目前之支持单方，附加式的写入。
## HDFS基本概念
### 块（Blocks）
数据存储的磁盘是由无数的数据块组成的。块大小指的是最小可读取的数据量。基于磁盘的文件系统（比如Windows操作系统）同样也使用块来管理数据，
只不过文件系统的节点通常是由多个磁盘节点组成的。一般文件系统的块是几个KB，而磁盘数据块通常是512B。这样的块大小已经可以满足一般用户对于任意大小文件的读写。
当然，有些操作系统还支持块级的操作，比如Linux中的df和fsck命令。

HDFS同样也是基于块构建的，只不过它的块很大（默认是128M）。就像磁盘上的文件系统一样，HDFS上的文件也是被拆分成很多块，作为独立单元来存储的。

在分布式文件系统中引入“块”的抽象概念，能来很多显而易见的好处：
1. 由于没有要求一个文件的块全部存储在一个磁盘上，块就可以分布在整个集群的任意位置上，同时块的数量也不受制于单台机器的磁盘容量限制，因此能够存储文件的大小自然比单机要大得多。
2. 使用抽象块而不是文件来管理使得系统更加简化。由于块都是固定大小，使得文件在磁盘上存储容量的计算更加方便。
3. 在高可用性和高容错率方面，块的使用也为复制带来了便利。
### 名称节点（Namenodes）和数据节点（Datanodes）
* 名称节点

名称节点管理文件系统的命名空间。它维护文件系统树以及树上所有文件和目录的元数据。这些信息都通过两类文件固定地写入到了本地磁盘中：命名空间镜像（namespace image）和修改日志（editlog）。同时，名称节点中还保存了任意文件的块所分布的数据节点；不过这部分信息没有固定写入磁盘，因为这部分信息是在系统启动时由数据节点提供的信息构建的。

名称节点是HDFS中非常关键的部分。如果节点的数据损坏，即使数据节点中的数据完好无损，由于HDFS无法获知文件与块之间的关联信息，也就无法获得文件的数据块。Hadoop提供了两种机制来提高系统的容错率：备份名称节的数据或提供备用名称节点。

* 数据节点

数据节点是文件系统的实际苦力。他们接受客户端或名称节点存储和读取命令，实现文件的存储和读取。另外，名称节点会周期性的将节点上存储块的列表汇报给名称节点。


客户端（client）接受用户的指令，通过与名称节点和数据节点沟通来访问文件系统。客户端给用户提供了非常友好的接口，因此用户无需知道名称节点和数据节点运作的细节，就可以实现文件管理。
